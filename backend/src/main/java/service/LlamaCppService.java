package service;

import jakarta.inject.Singleton;
import java.io.File;


import de.kherud.llama.LlamaModel;
import de.kherud.llama.ModelParameters;
import de.kherud.llama.InferenceParameters;
import de.kherud.llama.LlamaOutput;
import de.kherud.llama.args.LogFormat;

/**
 * Singleton service responsible for managing the local LLM instance using the Llama.cpp binding.
 * This service encapsulates the complex logic of loading the model and running inferences.
 */
@Singleton
public class LlamaCppService {

    private final LlamaModel model;


    /**
     * Constructor for the service. It handles the critical step of loading the model
     * from disk into memory during application startup.
     */
    public LlamaCppService() {
        var modelPath = "models/qwen.gguf";
        if (!new File(modelPath).exists()) {
            throw new RuntimeException("ERREUR : Fichier introuvable: " + modelPath);
        }
        var modelParams = new ModelParameters().setModel(modelPath).setGpuLayers(99);
        LlamaModel.setLogger(LogFormat.TEXT, (level, message) -> {});
        this.model = new LlamaModel(modelParams);
    }


    /**
     * Generates a structured exercise response based on a teacher's specification.
     * @param specification The natural language description of the exercise.
     * @return The raw text output generated by the LLM (expected to be in a parseable format, e.g., JSON/Markdown).
     */
    public String generateExercise(String specification) {
        var prompt = "Génere un exercice Java sur : " + specification + "\nRéponse:";
        var params = new InferenceParameters(prompt).setTemperature(0.1f).setNPredict(1024);
        var result = new StringBuilder();
        for (LlamaOutput output : model.generate(params)) {
            result.append(output);
        }
        return result.toString();
    }
}